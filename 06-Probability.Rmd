---
output:
  html_document: default
  bookdown::gitbook:
    lib_dir: "book_assets"
    includes:
      in_header: google_analytics.html
  pdf_document: default
---
<!-- # Probability -->
# Probabilidad {#probability}

```{r echo=FALSE,message=FALSE}
library(dplyr)
library(reshape2)
library(tidyr)
library(ggplot2)
library(knitr)
library(readr)
library(cowplot)
# load the NHANES data library
library(NHANES)

```

<!-- Probability theory is the branch of mathematics that deals with chance and uncertainty.  It forms an important part of the foundation for statistics, because it provides us with the mathematical tools to describe uncertain events.  The study of probability arose in part due to interest in understanding games of chance, like cards or dice.  These games provide useful examples of many statistical concepts, because when we repeat these games the likelihood of different outcomes remains (mostly) the same. However, there are deep questions about the meaning of probability that we will not address here; see Suggested Readings at the end if you are interested in learning more about this fascinating topic and its history. -->
La teoría de probabilidad es la rama de las matemáticas que trata con el azar y la incertidumbre. Forma parte importante de los fundamentos de la estadística, porque nos provee con las herramientas matemáticas para describir eventos inciertos. El estudio de la probabilidad inició en parte debido al interés de entender los juegos de azar, como las cartas o los dados. Estos juegos proveen de ejemplos útiles de muchos conceptos estadísticos, porque cuando repetimos estos juegos la probabilidad de diferentes resultados se mantiene (mayormente) igual. Sin embargo, existen preguntas profundas sobre el significado de la probabilidad que no abordaremos aquí; ve las Lecturas Sugeridas al final del capítulo si estás interesade en aprender más acerca de este tema fascinante y su historia.

<!-- ## What is probability? -->
## ¿Qué es la probabilidad?

<!-- Informally, we usually think of probability as a number that describes the likelihood of some event occurring, which ranges from zero (impossibility) to one (certainty).  Sometimes probabilities will instead be expressed in percentages, which range from zero to one hundred, as when the weather forecast predicts a twenty percent chance of rain today.  In each case, these numbers are expressing how likely that particular event is, ranging from absolutely impossible to absolutely certain. -->
De manera informal, usualmente pensamos a la probabilidad (probability) como el número que describe la probabilidad (likelihood) de que un evento ocurra, que va de un rango desde cero (imposibilidad) a uno (certeza). A veces las probabilidades se expresarán en porcentajes, que van de un rango de cero a cien, como cuando en el pronóstico del tiempo se predice que hay un veinte por ciento de probabilidad de lluvia para hoy. En cada caso, estos números expresan qué tan probable es que suceda un evento en particular, desde la absoluta imposibilidad hasta la absoluta certeza.

<!-- To formalize probability theory, we first need to define a few terms: -->
Para formalizar la teoría de probabilidad, primero necesitamos definar algunos términos:

<!-- - An **experiment** is any activity that produces or observes an outcome.  Examples are flipping a coin, rolling a 6-sided die, or trying a new route to work to see if it's faster than the old route. -->
- Un **experimento** es cualquier actividad que produce u observa un resultado. Ejemplos son el lanzar una moneda, rodar un dado, o probar una nueva ruta al trabajo para ver si es más rápida que la vieja ruta.
<!-- - The **sample space** is the set of possible outcomes for an experiment.  We represent these by listing them within a set of squiggly brackets. For a coin flip, the sample space is {heads, tails}.  For a six-sided die, the sample space is each of the possible numbers that can appear: {1,2,3,4,5,6}.  For the amount of time it takes to get to work, the sample space is all possible real numbers greater than zero (since it can't take a negative amount of time to get somewhere, at least not yet). We won't bother trying to write out all of those numbers within the brackets. -->
- El **espacio muestral** es el conjunto de posibles resultados de un experimento. Los representamos enlistándolos dentro de un par de llaves ( {} ). En el caso de un lanzamiento de moneda, el espacio muestral es {cara, cruz}. En el caso de un dado de seis lados, el espacio muestral es cada uno de los posibles números que pueden aparecer: {1,2,3,4,5,6}. Para el tiempo que toma llegar al trabajo, el espacio muestral son todos los posibles números reales mayores a cero (porque no se puede llegar a algún lugar en un tiempo negativo, al menos aún no se puede). No nos preocuparemos en tratar de escribir todos esos números entre las llaves.
<!-- - An **event** is a subset of the sample space.  In principle it could be one or more of possible outcomes in the sample space, but here we will focus primarily on *elementary events* which consist of exactly one possible outcome.  For example, this could be obtaining heads in a single coin flip, rolling a 4 on a throw of the die, or taking 21 minutes to get home by the new route. -->
- Un **evento** es un subconjunto del espacio muestral. En principio puede ser uno o más de los posibles resultados en el espacio muestral, pero aquí nos enfocaremos principalmente en *eventos elementales* que consisten en exactamente un solo posible resultado. Por ejemplo, esto podría ser el obtener cara en un solo lanzamiento de moneda, sacar un 4 en un lanzamiento de dado, o tardar 21 minutos en llegar a casa en la nueva ruta.

<!-- Now that we have those definitions, we can outline the formal features of a probability, which were first defined by the Russian mathematician Andrei Kolmogorov. These are the features that a value *has* to have if it is going to be a probability. Let's say that we have a sample space defined by N independent events, ${E_1, E_2, ... , E_N}$, and $X$ is a random variable denoting which of the evets has happend.  $P(X=E_i)$ is the probability of event $i$: -->
Ahora que tenemos estas definiciones, podemos delinear las características formales de una probabilidad, las cuales fueron primero definidas por el matemático ruso Andrei Kolmogorov. Estas son las características que *debe* tener un valor si va a ser una probabilidad. Digamos que tenemos un espacio muestral definido por N eventos independientes, ${E_1, E_2, ... , E_N}$, y $X$ es una variable aleatoria que denota cuál de los eventos ha sucedido. $P(X=E_i)$ es la probabilidad de un evento $i$:

<!-- - Probability cannot be negative: $P(X=E_i) \ge 0$ -->
- La probabilidad no puede ser negativa: $P(X=E_i) \ge 0$
<!-- - The total probability of all outcomes in the sample space is 1; that is,  if the , if we take the probability of each Ei and add them up, they must sum to 1. We can express this using the summation symbol $\sum$: -->
- La probabilidad total de todos los resultados en un espacio muestral es 1; esto es, si tomamos la probabilidad de cada $E_i$ y las sumamos, deben dar un total de 1. Podemos expresar esto usando el símbolo de sumatoria $\sum$:
$$
\sum_{i=1}^N{P(X=E_i)} = P(X=E_1) + P(X=E_2) + ... + P(X=E_N) = 1
$$
<!-- This is interpreted as saying "Take all of the N elementary events, which we have labeled from 1 to N, and add up their probabilities. These must sum to one."  -->
Esto se interpreta como "Toma todos los eventos elementales N, que hemos etiquetado desde 1 hasta N, y suma sus probabilidades. Estas deben sumar 1."
<!-- - The probability of any individual event cannot be greater than one: $P(X=E_i)\le 1$.  This is implied by the previous point; since they must sum to one, and they can't be negative, then any particular probability must be less than or equal to one. -->
- La probabilidad de cualquier evento individual no puede ser mayor a uno: $P(X=E_i)\le 1$. Esto es sugerido por el punto anterior; como deben de sumar uno, y no pueden ser números negativos, entonces cualquier probabilidad en particular debe ser menor o igual a uno.

<!-- ## How do we determine probabilities? -->
## ¿Cómo determinamos probabilidades?

<!-- Now that we know what a probability is, how do we actually figure out what the probability is for any particular event? -->
Ahora que sabemos lo que es la probabilidad, ¿cómo hacemos para realmente averiguar cuál es la probabilidad de que suceda algún evento en particular?

<!-- ### Personal belief -->
### Creencia personal 

<!-- Let's say that I asked you what the probability was that the Beatles would have been equally successful if they had not replaced their original drummer Pete Best with Ringo Starr in 1962.  We will define "success" in terms of the number of number-one hits on the Billboard Hot 100 (which we refer to as $N_{hits}$); the Beatles had 20 such number-one hits, so the sample space is {$N_{hits} < 20$,$N_{hits} \ge 20$ }.  We can't actually do the experiment to find the outcome. However, most people with knowledge of the Beatles would be willing to at least offer a guess at the probability of this event.  In many cases personal knowledge and/or opinion is the only guide we have determining the probability of an event, but this is not very scientifically satisfying. -->
Digamos que te pregunto cuál hubiera sido la probabilidad de que los Beatles hubieran sido igualmente exitosos si no hubieran reemplazado al baterista original Pete Best por Ringo Starr en 1962. Definiremos "éxito" en términos de la cantidad de hits número uno en el Billboard Hot 100 (al que nos referiremos como $N_{hits}$); los Beatles tuvieron 20 de esos hits número uno, por lo que el espacio muestral es { $N_{hits} < 20$,$N_{hits} \ge 20$ }. No podemos realmente hacer el experimento para averiguar el resultado. Sin embargo, la mayoría de las personas con conocimiento de los Beatles estarían dispuestos a por lo menos a tratar de adivinar la probabilidad de este evento. En muchos casos el conocimiento personal y/u opinión es la única guía que tenemos para determinar la probabilidad de un evento, pero esto no es muy satisfactorio científicamente.

<!-- ### Empirical frequency {#empirical-frequency} -->
### Frecuencia empírica {#empirical-frequency}

<!-- Another way to determine the probability of an event is to do the experiment many times and count how often each event happens.  From the relative frequency of the different outcomes, we can compute the probability of each outcome.  For example, let's say that we are interested in knowing the probability of rain in San Francisco.  We first have to define the experiment --- let's say that we will look at the National Weather Service data for each day in 2017 and determine whether there was any rain at the downtown San Francisco weather station. -->
Otra manera de determinar la probabilidad de un evento es el hacer un experimento muchas veces y contar cuántas veces sucedió cada evento. Podemos calcular la probabilidad de cada resultado a partir de la frecuencia relativa de los diferentes resultados. Por ejemplo, digamos que estás interesado en saber la probabilidad de lluvia en San Francisco. Primero debemos definir nuestro experimento --- digamos que miraremos los datos del *National Weather Service* para cada día en 2017 y determinaremos si hubo lluvia en la estación del clima del centro de San Francisco.

```{r RainInSF,echo=FALSE,warning=FALSE,message=FALSE}
# load data on rain in San Francisco and compute probability
# from https://www.ncdc.noaa.gov/
SFrain <- read_csv("data/SanFranciscoRain/1329219.csv")

# create a new variable indicating whether it rained on each day
SFrain <- 
  SFrain %>%
  mutate(rainToday = as.integer(PRCP > 0))

SFrain_summary <- 
  SFrain %>%
  summarize(
    nRainyDays = sum(rainToday),
    nDaysMeasured = n(),
    pRainInSF = nRainyDays / nDaysMeasured
  ) 
names(SFrain_summary) <- c('Number of rainy days','Number of days measured', 'P(rain)')
kable(SFrain_summary)
```


<!-- According to these data, in 2017 there were 73 rainy days.  To compute the probability of rain in San Francisco, we simply divide the number of rainy days by the number of days counted (365), giving P(rain in SF in 2017) = 0.2. -->
De acuerdo con estos datos, en 2017 hubo 73 días lluviosos. Para calcular la probabilidad de lluvia en San Francisco, simplemente dividimos el número de días lluviosos entre el número de días totales (365), dando una P(lluvia en SF en 2017) = 0.2

<!-- How do we know that empirical probability gives us the right number? The answer to this question comes from the *law of large numbers*, which shows that the empirical probability will approach the true probability as the sample size increases.  We can see this by simulating a large number of coin flips, and looking at our estimate of the probability of heads after each flip.  We will spend more time discussing simulation in a later chapter; for now, just assume that we have a computational way to generate a random outcome for each coin flip. -->
¿Cómo sabemos que la probabilidad empírica nos dará el número correcto? La respuesta a esta pregunta viene de la *ley de números grandes*, que muestra que la probabilidad empírica se aproximará a la verdadera probabilidad conforme el tamaño de la muestra se incrementa. Podemos ver esto simulando un gran número de lanzamientos de moneda, y observando nuestra estimación de la probabilidad de que caiga cara después de cada lanzamiento. Pasaremos más tiempo discutiendo simulaciones en un capítulo posterior; por ahora, sólo asumamos que tenemos una manera computacional de generar un resultado aleatorio para cada lanzamiento de moneda.

```{r FlipSim,echo=FALSE}

set.seed(12345) # set the seed so that the outcome is consistent
nsamples <- 30000 # how many flips do we want to make?
# create some random coin flips using the rbinom() function with
# a true probability of 0.5

sampDf <- 
  tibble( 
    trial_number = seq(nsamples), 
    outcomes = rbinom(nsamples, 1, 0.5)
  ) %>%
  mutate(mean_probability = cumsum(outcomes) / seq_along(outcomes))

p1 <- sampDf %>% 
  slice(10:nsamples) %>% # start with a minimum sample of 10 flips
  ggplot(aes(x = trial_number, y = mean_probability)) +
  geom_hline(yintercept = 0.5, color = "blue", linetype = "dashed") +
  geom_line() +
  labs(
    x = "Number of trials",
    y = "Estimated probability of heads"
  )
```

<!-- The left panel of Figure \@ref(fig:ElectionResults) shows that as the number of samples (i.e., coin flip trials) increases, the estimated probability of heads converges onto the true value of 0.5. However, note that the estimates can be very far off from the true value when the sample sizes are small.  A real-world example of this was seen in the 2017 special election for the US Senate in Alabama, which pitted the Republican Roy Moore against Democrat Doug Jones.  The right panel of Figure \@ref(fig:ElectionResults) shows the relative amount of the vote reported for each of the candidates over the course of the evening, as an increasing number of ballots were counted. Early in the evening the vote counts were especially volatile, swinging from a large initial lead for Jones to a long period where Moore had the lead, until finally Jones took the lead to win the race.  -->
El panel izquierdo de la Figura \@ref(fig:ElectionResults) muestra que conforme el número de muestras (i.e., ensayos de lanzamiento de moneda) incrementa, la probabilidad estimada de obtener cara converge en el valor verdadero de 0.5. Sin embargo, nota que las estimaciones pueden estar bastante lejos del valor verdadero cuando los tamaños de muestra son pequeños. Un ejemplo del mundo real sobre esto se puede ver en la elección especial de 2017 para el Senado de EUA en Alabama, que enfrentó al Republicano Roy Moore contra el Demócrata Doug Jones. El panel derecho de la Figura \@ref(fig:ElectionResults) muestra la cantidad relativa de votos reportados para cada uno de los candidatos en el curso de la tarde del día de la elección, conforme un número creciente de boletas eran contadas. Temprano en la tarde el conteo de votos era especialmente volátil, balanceándose desde una ventaja inicial grande para Jones hasta un periodo largo donde Moore tenía la ventaja, hasta que finalmente Jones tomó la delantera ganando la contienda.

<!-- Left: A demonstration of the law of large numbers.  A coin was flipped 30,000 times, and after each flip the probability of heads was computed based on the number of heads and tail collected up to that point.  It takes about 15,000 flips for the probability to settle at the true probability of 0.5. Right: Relative proportion of the vote in the Dec 12, 2017 special election for the US Senate seat in Alabama, as a function of the percentage of precincts reporting. These data were transcribed from https://www.ajc.com/news/national/alabama-senate-race-live-updates-roy-moore-doug-jones/KPRfkdaweoiXICW3FHjXqI/ -->
```{r ElectionResults, echo=FALSE,message=FALSE,fig.cap='Izquierda: Una demostración de la ley de los números grandes. Una moneda fue lanzada 30,000 veces, y después de cada lanzamiento la probabilidad de obtener cara era calculada basada en el número de caras y cruces observadas hasta ese punto. Toma un aproximado de 15,000 lanzamientos para que la probabilidad se quede establecida en la probabilidad verdadera de 0.5. Derecha: Proporción relativa de votos el 12 de diciembre de 2017 durante la elección especial para el asiento de Alabama en el Senado de EUA, como una función del porcentaje de casillas electorales reportadas. Estos datos fueron transcritos de https://www.ajc.com/news/national/alabama-senate-race-live-updates-roy-moore-doug-jones/KPRfkdaweoiXICW3FHjXqI/ ',fig.width=8,fig.height=4,out.height='50%'}

electionReturns <- 
  read_csv(
    "data/03/alabama_election_returns.csv"
  ) %>%
  gather(candidate, pctVotes, -pctResp)

p2 <- electionReturns %>% 
  ggplot(aes(pctResp, pctVotes, color = candidate)) +
  geom_line(aes(linetype=candidate),size = 1) +
  scale_color_manual(values = c("#9999CC", "#CC6666")) +
  labs(
    x = "Percentage of precincts reporting",
    y = "Percentage of votes"
  ) +
  theme(legend.position = c(.7,0.8)) 
plot_grid(p1, p2)
```

<!-- These two examples show that while large samples will ultimately converge on the true probability, the results with small samples can be far off.  Unfortunately, many people forget this and overinterpret results from small samples.  This was referred to as the *law of small numbers* by the psychologists Danny Kahneman and Amos Tversky, who showed that people (even trained researchers) often behave as if the law of large numbers applies even to small samples, giving too much credence to results from small datasets.  We will see examples throughout the course of just how unstable statistical results can be when they are generated on the basis of small samples. -->
Estos dos ejemplos muestran que mientras las muestras grandes últimamente convergen en la probabilidad verdadera, los resultados de muestras pequeñas pueden estar muy equivocados. Desafortunadamente, muchas personas olvidan esto y sobreinterpretan resultados de muestras pequeñas. Esto ha sido referido como la *ley de números pequeños* por los psicólogos Danny Kahneman y Amos Tversky, quienes mostraron que la gente (incluso investigadores entrenados) frecuentemente se comportan como si la ley de los números grandes aplicara también en las muestras pequeñas, dando demasiada credibilidad a resultados de bases de datos pequeñas. A lo largo del curso veremos ejemplos de qué tan inestables pueden ser los resultados estadísticos cuando son generados en base a muestras pequeñas.

<!-- ### Classical probability -->
### Probabilidad clásica

<!-- It's unlikely that any of us has ever flipped a coin tens of thousands of times, but we are nonetheless willing to believe that the probability of flipping heads is 0.5.  This reflects the use of yet another approach to computing probabilities, which we refer to as *classical probability*.  In this approach, we compute the probability directly based on our knowledge of the situation.  -->
Es poco probable que cualquiera de nosotros haya lanzado una moneda decenas de miles de veces, pero sin importar eso estamos dispuestos a creer que la probabilidad de lanzar una moneda y que caiga cara es 0.5. Esto refleja el uso de otra aproximación más al cálculo de probabilidades, al cual nos referimos como *probabilidad clásica*. En esta aproximación, calculamos la probabilidad directamente desde nuestro conocimiento de la situación.

<!-- Classical probability arose from the study of games of chance such as dice and cards.  A famous example arose from a problem encountered by a  French gambler who went by the name of Chevalier de Méré.  de Méré played two different dice games: In the first he bet on the chance of at least one six on four rolls of a six-sided die, while in the second he bet on the chance of at least one double-six on 24 rolls of two dice.  He expected to win money on both of these gambles, but he found that while on average he won money on the first gamble, he actually lost money on average when he played the second gamble many times. To understand this he turned to his friend, the mathematician Blaise Pascal, who is now recognized as one of the founders of probability theory.  -->
La probabilidad clásica surgió del estudio de juegos de azar como los dados y las cartas. Un ejemplo famoso surgió del problema que se encontró un jugador francés que se conocía por el nombre de Chevalier de Méré. de Méré jugaba dos diferentes juegos de dados: En el primero él apostaba en la probabilidad de obtener por lo menos un seis en cuatro lanzamientos de un dado de seis lados, mientras que en el segundo juego apostaba en la probabilidad de obtener por lo menos un doble seis en 24 lanzamientos de dos dados. Él esperaba ganar dinero en ambos juegos, pero encontró que mientras que en promedio él ganaba dinero en el primer juego, realmente terminaba perdiendo dinero en promedio cuando jugaba el segundo juego muchas veces. Para entender esto buscó a su amigo, el matemático Blaise Pascal, quien es reconocido como uno de los fundadores de la teoría de probabilidad.

<!-- How can we understand this question using probability theory?  In classical probability, we start with the assumption that all of the elementary events in the sample space are equally likely; that is, when you roll a die, each of the possible outcomes ({1,2,3,4,5,6}) is equally likely to occur.  (No loaded dice allowed!)  Given this, we can compute the probability of any individual outcome as one divided by the number of possible outcomes: -->
¿Cómo podemos entender esta pregunta usando teoría de probabilidad? En probabilidad clásica, comenzamos con una suposición de que todos los eventos elementales en el espacio muestral son igualmente probables; esto es, cuando lanzas un dado, cada uno de los posibles resultados ({1,2,3,4,5,6}) es igualmente probable que ocurra. (¡No se permiten dados cargados (o manipulados)! Considerando esto, podemos calcular la probabilidad de cualquier resultado individual como un uno dividido entre el número de resultados posibles:

$$
P(resultados_i) = \frac{1}{\text{número de resultados posibles}}
$$

<!-- For the six-sided die, the probability of each individual outcome is 1/6.  -->
Para el dado de seis lados, la probabilidad de cada resultados individual es 1/6.

<!-- This is nice, but de Méré was interested in more complex events, like what happens on multiple dice throws.  How do we compute the probability of a complex event (which is a *union* of single events), like rolling a six on the first *or* the second throw?  -->
Esto está bien, pero de Méré estaba interesado en eventos más complejos, como lo que sucede en múltiples lanzamientos de dados. ¿Cómo calculamos la probabilidad de un evento complejo (el cual es la *unión* de eventos simples), como obtener un seis en el primer *o* el segundo lanzamiento?

<!-- We represent the union of events mathematically using the $\cup$ symbol: for example, if the probability of rolling a six on the first throw is referred to as $P(Roll1_{throw1})$ and the probability of rolling a six on the second throw is $P(Roll1_{throw2})$, then the union is referred to as $P(Roll1_{throw1} \cup Roll1_{throw2})$. -->
La unión de eventos la representamos matemáticamente usando el símbolo $\cup$: por ejemplo, si la probabilidad de obtener un seis en el primer lanzamiento es referido como $P(Roll6_{throw1})$ y la probabilidad de obtener un seis en el segundo lanzamiento es $P(Roll6_{throw2})$, entonces la unión es referida como $P(Roll6_{throw1} \cup Roll6_{throw2})$.

<!-- de Méré thought (incorrectly, as we will see below) that he could simply add together the probabilities of the individual events to compute the probability of the combined event, meaning that the probability of rolling a six on the first or second roll would be computed as follows: -->
de Méré pensó (incorrectamente, como veremos más abajo) que simplemente podía sumar las probabilidades de cada evento individual para calcular la probabilidad del evento combinado, significando que la probabilidad de obtener un seis en el primer o segundo lanzamiento se calcularía de la siguiente manera:

$$
P(Roll6_{throw1}) = 1/6
$$
$$
P(Roll6_{throw2}) = 1/6
$$

$$
de Méré's \ error:
$$
$$
P(Roll6_{throw1} \cup Roll6_{throw2}) = P(Roll6_{throw1}) + P(Roll6_{throw2}) = 1/6 + 1/6 = 1/3
$$

<!-- de Méré reasoned based on this incorrect assumption that the probability of at least one six in four rolls was the sum of the probabilities on each of the individual throws: $4*\frac{1}{6}=\frac{2}{3}$.  Similarly, he reasoned that since the probability of a double-six when throwing two dice is 1/36, then the probability of at least one double-six on 24 rolls of two dice would be $24*\frac{1}{36}=\frac{2}{3}$.  Yet, while he consistently won money on the first bet, he lost money on the second bet.  What gives? -->
de Méré creyó, basado en esta suposición incorrecta, que la probabilidad de obtener al menos un seis en cuatro lanzamientos era la suma de las probabilidades de cada lanzamiento individual: $4*\frac{1}{6}=\frac{2}{3}$. De manera similar, creyó que dado que la probabilidad de un doble seis al lanzar un dado es 1/36, entonces la probabilidad de obtener al menos un doble seis en 24 lanzamientos de dos dados sería $24*\frac{1}{36}=\frac{2}{3}$. Sin embargo, mientras consistentemente él ganaba dinero en la primera apuesta, perdía dinero con la segunda. ¿Por qué pasaba esto?

<!-- To understand de Méré's error, we need to introduce some of the rules of probability theory.  The first is the *rule of subtraction*, which says that the probability of some event A *not* happening is one minus the probability of the event happening: -->
Para entender el error de de Méré, necesitamos presentar algunas de las reglas de la teoría de probabilidad. La primera es la *regla de substracción/resta*, que dice que la probabilidad de que algún evento A *no* suceda es uno menos la probabilidad de que el evento suceda:

$$
P(\neg A) = 1 - P(A)
$$

<!-- where $\neg A$ means "not A". This rule derives directly from the axioms that we discussed above; because A and $\neg A$ are the only possible outcomes, then their total probability must sum to 1.  For example, if the probability of rolling a one in a single throw is $\frac{1}{6}$, then the probability of rolling anything other than a one is $\frac{5}{6}$. -->
donde $\neg A$ significa "no A". Esta regla se deriva directamente de los axiomas que discutimos arriba; porque A y $\neg A$ son los únicos posibles resultados, entonces su probabilidad total debe sumar 1. Por ejemplo, si la probabilidad de obtener un uno en un solo lanzamiento es $\frac{1}{6}$, entonces la probabilidad de obtener cualquier otro número que no fuera uno es $\frac{5}{6}$.

<!-- A second rule tells us how to compute the probability of a conjoint event -- that is, the probability that both of two events will occur. We refer to this as an *intersection*, which is signified by the $\cap$ symbol; thus, $P(A \cap B)$ means the probability that both A and B will occur. -->
Una segunda regla nos dice cómo calcular la probabilidad de un evento conjunto -- esto es, la probabilidad de que ambos eventos ocurran. Nos referimos a esto como una *intersección*, que es representada por el símbolo $\cap$; por lo tanto, $P(A \cap B)$ significa la probabilidad de que ambos A y B sucedan.

<!-- This version of the rule tells us how to compute this quantity in the special case when the two events are independent from one another; we will learn later exactly what the concept of *independence* means, but for now we can just take it for granted that the two die throws are independent events.  We compute the probability of the union of two independent events by simply multiplying the probabilities of the individual events: -->
Esta versión de la regla nos dice cómo calcular esta cantidad en el caso especial cuando dos eventos son independientes uno de otro; aprenderemos después exactamente qué significa el concepto de *independencia*, pero por ahora podemos dar por sentado que los dos lanzamientos de dados son eventos independientes. Calculamos la probabilidad de la intersección de dos eventos independientes simplemente multiplicando las probabilidades de los eventos individuales:

<!-- P(A \cap B) = P(A) * P(B)\ \text{if and only if A and B are independent} -->
$$
P(A \cap B) = P(A) * P(B)\ \text{si y sólo si A y B con independientes}
$$
<!-- Thus, the probability of throwing a six on both of two rolls is $\frac{1}{6}*\frac{1}{6}=\frac{1}{36}$. -->
Por lo tanto, la probabilidad de obtener un seis en ambos lanzamientos de dados es $\frac{1}{6}*\frac{1}{6}=\frac{1}{36}$.

<!-- The third rule tells us how to add together probabilities - and it is here that we see the source of de Méré's error.  The addition rule tells us that to obtain the probability of either of two events occurring, we add together the individual probabilities, but then subtract the likelihood of both occurring together: -->
La tercera regla nos dice cómo sumar las probabilidades - y es aquí donde vemos el origen del error de de Méré. La *regla de la suma* nos dice que para obtener la probabilidad de que cualquiera de dos eventos ocurran, debemos sumar las probabilidades individuales, pero luego debemos restar la probabilidad de que ocurran ambos eventos juntos:

$$
P(A \cup B) = P(A) + P(B) - P(A \cap B)
$$
<!-- In a sense, this prevents us from counting those instances twice, and that's what distinguishes the rule from de Méré's incorrect computation. Let's say that we want to find the probability of rolling 6 on either of two throws.  According to our rules: -->
En un sentido, esto evita que contemos esos eventos conjuntos dos veces, eso es lo que distingue a esta regla del cálculo que de Méré había hecho incorrectamente. Digamos que queremos encontrar la probabilidad de obtener 1 en cualquiera de dos lanzamientos. De acuerdo a nuestras reglas:


$$
P(Roll1_{throw1} \cup Roll1_{throw2}) 
$$
$$
= P(Roll1_{throw1}) + P(Roll1_{throw2}) - P(Roll1_{throw1} \cap Roll1_{throw2}) 
$$
$$
= \frac{1}{6} + \frac{1}{6} - \frac{1}{36} = \frac{11}{36}
$$

<!-- Each cell in this matrix represents one outcome of two throws of a die, with the columns representing the first throw and the rows representing the second throw. Cells shown in red represent the cells with a one in either the first or second throw; the rest are shown in blue. -->
```{r ThrowMatrix, echo=FALSE,fig.cap='Cada celda de esta matriz representa un resultado de dos lanzamientos de un solo dado, donde las columnas representan el primer lanzamiento y las filas representan el segundo lanzamiento. Las celdas en rojo representan celdas con un uno ya sea en el primer o en el segundo lanzamiento; el resto se muestran en azul. ',fig.width=4,fig.height=4,out.height='50%'}
imgmtx <-
  matrix(0, nrow = 6, ncol = 6) 

imgmtx[, 1] <- 1
imgmtx[1, ] <- 1

plot <- 
  imgmtx %>% 
  melt() %>% 
  ggplot(aes(Var1, Var2, fill = value)) +
  scale_fill_gradientn(colours=c("#0000FFFF","#FFFFFFFF","#FF0000FF")) +
  geom_raster(interpolate = FALSE)

for (i in seq(0.5, 6.5)) {
  plot <- 
    plot + geom_hline(yintercept = i, color = "white")
  plot <- 
    plot + geom_vline(xintercept = i, color = "white")
  for (j in seq(0.5, 6.5)) {
    plot <- 
      plot + annotate(
        "text", 
        x = i + 0.5, y = j + 0.5, 
        label = sprintf("%d,%d", i + 0.5, j + 0.5), 
        color = "white")
  }
}

plot +
  theme_minimal() +
  theme(
    axis.line = element_blank(), 
    axis.text.x = element_blank(),
    axis.text.y = element_blank(), 
    axis.ticks = element_blank(),
    legend.position = "none"
  ) +
  labs(
    x = "Throw 1",
    y = "Throw 2"
  )

```

<!-- Let's use a graphical depiction to get a different view of this rule. Figure \@ref(fig:ThrowMatrix) shows a matrix representing all possible combinations of results across two throws, and highlights the cells that involve a one on either the first or second throw. If you count up the cells in red you will see that there are 11 such cells. This shows why the addition rule gives a different answer from de Méré's; if we were to simply add together the probabilities for the two throws as he did, then we would count (1,1) towards both, when it should really only be counted once. -->
Usemos una representación gráfica para obtener una diferente vista de esta regla. La Figura \@ref(fig:ThrowMatrix) muestra una matriz representando todas las posibles combinaciones de resultados de dos lanzamientos de dados, y subraya las celdas que involucran un uno ya sea en el primer o en el segundo lanzamiento. Si cuentas las celdas en rojo verás que hay 11 celdas con ese resultado. Esto muestra por qué la regla de la suma da una respuesta diferente a la de de Méré; si simplemente sumáramos las probabilidades de los dos lanzamientos como él lo hizo, entonces terminaríamos contando la celda de (1,1) en ambos, cuando solamente debería contar una sola vez.

<!-- ### Solving de Méré's problem -->
### Resolviendo el problema de de Méré

<!-- Blaise Pascal used the rules of probability to come up with a solution to de Méré's problem.  First, he realized that computing the probability of at least one event out of a combination was tricky, whereas computing the probability that something does not occur across several events is relatively easy -- it's just the product of the probabilities of the individual events.  Thus, rather than computing the probability of at least one six in four rolls, he instead computed the probability of no sixes across all rolls: -->
Blaise Pascal usó la reglas de la probabilidad para idear una solución al problema de de Méré. Primero, se dio cuenta que calcular la probabilidad de al menos un evento de una combinación era complicado, mientras que calcular la probabilidad de que algo no ocurra a lo largo de varios eventos es relativamente fácil -- es sólo el producto de las probabilidades de los eventos individuales. Por lo tanto, en lugar de calcular la probabilidad de al menos un seis en cuatro lanzamientos, calculó la probabilidad de ningún seis a lo largo de todos los lanzamientos:

<!-- P(\text{no sixes in four rolls}) -->
$$
P(\text{ningún seis en cuatro lanzamientos})
$$
$$
= \frac{5}{6}*\frac{5}{6}*\frac{5}{6}*\frac{5}{6}=\bigg(\frac{5}{6}\bigg)^4=0.482
$$

<!-- He then used the fact that the probability of no sixes in four rolls is the complement of at least one six in four rolls (thus they must sum to one), and used the rule of subtraction to compute the probability of interest: -->
Pascal entonces usó el hecho de que la probabilidad de ningún seis en cuatro lanzamientos es el complemento de al menos un seis en cuatro lanzamientos (por lo que deben sumar uno), y usó la regla de la resta para calcular la probabilidad de interés:

<!-- P(\text{at least one six in four rolls}) = 1 - \bigg(\frac{5}{6}\bigg)^4=0.517 -->
$$
P(\text{al menos un seis en cuatro lanzamientos}) = 1 - \bigg(\frac{5}{6}\bigg)^4=0.517
$$

<!-- de Méré's gamble that he would throw at least one six in four rolls has a probability of greater than 0.5, explaning why de Méré made money on this bet on average. -->
La apuesta de de Méré de que obtendría al menos un seis en cuatro lanzamientos tiene una probabilidad mayor a 0.5, lo que explica por qué de Méré ganaba dinero en esta apuesta en promedio.

<!-- But what about de Méré's second bet?  Pascal used the same trick: -->
¿Pero qué pasaba con la segunda apuesta de de Méré? Pascal usó el mismo truco:

<!-- \text{no double six in 24 rolls} -->
$$
P(\text{no doble seis en 24 lanzamientos}) = \bigg(\frac{35}{36}\bigg)^{24}=0.509
$$
<!-- \text{at least one double six in 24 rolls} -->
$$
P(\text{al menos un doble seis en 24 lanzamientos}) = 1 - \bigg(\frac{35}{36}\bigg)^{24}=0.491
$$

<!-- The probability of this outcome was slightly below 0.5, showing why de Méré lost money on average on this bet.  -->
La probabilidad de este resultado era ligeramente menor a 0.5, mostrando por qué de Méré perdía dinero con esta apuesta en promedio. 

<!-- ## Probability distributions -->
## Distribuciones de probabilidad

<!-- A *probability distribution* describes the probability of all of the possible outcomes in an experiment. For example, on Jan 20 2018, the basketball player Steph Curry hit only 2 out of 4 free throws in a game against the Houston Rockets. We know that Curry's overall probability of hitting free throws across the entire season was 0.91, so it seems pretty unlikely that he would hit only 50% of his free throws in a game, but exactly how unlikely is it?  We can determine this using a theoretical probability distribution; during this course we will encounter a number of these probability distributions, each of which is appropriate to describe different types of data.  In this case, we use the *binomial* distribution, which provides a way to compute the probability of some number of successes out of a number of trials on which there is either success or failure and nothing in between (known as "Bernoulli trials")  given some known probability of success on each trial.  This distribution is defined as: -->
Una *distribución de probabilidad* describe la probabilidad de todos los posibles resultados en un experimento. Por ejemplo, el 20 de enero de 2018, el jugador de basketball Steph Curry anotó sólo 2 de 4 lanzamientos libres en un juego contra los Houston Rockets. Sabemos que la probabilidad general de Curry de anotar en lanzamientos libres a lo largo de toda la temporada fue de 0.91, por lo que parece bastante poco probable que sólo hubiera anotado 50% de sus lanzamientos libres en un juego, ¿pero exactamente qué tan poco probable es? Podemos determinar esto usando una distribución de probabilidad teórica; durante este curso nos encontraremos con una variedad de estas distribuciones de probabilidad, cada una es apropiada para describir diferentes tipos de datos. En este caso, usaremos la distribución *binomial*, que provee una manera de calcular la probabilidad de un número de éxitos en un número de ensayos en donde se puede tener sólo un éxito o un fallo y nada intermedio (conocidos como "ensayos de Bernoulli") dada una probabilidad conocida de éxito en cada ensayo. Esta distribución es definida como:

$$
P(k; n,p) = P(X=k) = \binom{n}{k} p^k(1-p)^{n-k}
$$

<!-- This refers to the probability of k successes on n trials when the probability of success is p.  You may not be familiar with $\binom{n}{k}$, which is referred to as the *binomial coefficient*. The binomial coefficient is also referred to as "n-choose-k" because it describes the number of different ways that one can choose k items out of n total items.  The binomial coefficient is computed as: -->
Esto se refiere a la probabilidad de k éxitos en n ensayos cuando la probabilidad de éxito es p. Tal vez no estés familiarizado con $\binom{n}{k}$, a la que nos referimos como el *coeficiente binomial*. El coeficiente binomial también es conocido como "n-choose-k" porque describe el número de maneras diferentes en las que uno puede elegir k elementos de un total de elementos n. El coeficiente binomial es calculado como:

$$
\binom{n}{k} = \frac{n!}{k!(n-k)!}
$$
<!-- where the exclamation point (!) refers to the *factorial* of the number: -->
donde el signo de exclamación (!) se refiere al *factorial* de un número:

$$
n! = \prod_{i=1}^n i = n*(n-1)*...*2*1 
$$


<!-- In the example of Steph Curry's free throws: -->
En el ejemplo de los lanzamientos libres de Steph Curry:

$$
P(2;4,0.91) = \binom{4}{2} 0.91^2(1-0.91)^{4-2} = 0.040
$$

<!-- This shows that given Curry's overall free throw percentage, it is very unlikely that he would hit only 2 out of 4 free throws.  Which just goes to show that unlikely things do actually happen in the real world. -->
Esto demuestra que dado el porcentaje de anotaciones en lanzamientos libres de Curry en la temporada, era bastante improbable que anotara sólo 2 de 4 tiros libres. Esto sólo muestra que en el mundo real efectivamente suceden cosas improbables.

<!-- ### Cumulative probability distributions -->
### Distribuciones de probabilidad acumuladas

<!-- Often we want to know not just how likely a specific value is, but how likely it is to find a value that is as extreme or more than a particular value; this will become very important when we discuss hypothesis testing in a later chapter.  To answer this question, we can use a *cumulative* probability distribution; whereas a standard probability distribution tells us the probability of some specific value, the cumulative distribution tells us the probability of a value as large or larger (or as small or smaller) than some specific value.  -->
Frecuentemente queremos conocer no sólo qué tan probable es un valor en específico, sino saber qué tan probable es encontrar un valor que es igualmente extremo o más extremo que cierto valor en particular; esto se volverá muy importante cuando discutamos las pruebas de hipótesis en un capítulo posterior. Para contestar esta pregunta, podemos usar la distribución de probabilidad *acumulada*; mientras que la distribución de probabilidad estándar nos dice la probabilidad de un valor en específico, la distribución acumulada nos dice la probabilidad de un valor igual de grande o mayor (o igual de pequeño o menor) que un valor específico.

<!-- In the free throw example, we might want to know: What is the probability that Steph Curry hits 2 *or fewer* free throws out of four, given his overall free throw probability of 0.91. To determine this, we could simply use the the binomial probability equation and plug in all of the possible values of k and add them together: -->
En el ejemplo del tiro libre, tal vez quisiéramos saber: ¿Cuál es la probabilidad de que Steph Curry anotara 2 *o menos* de un total de cuatro tiros libres, dado que su probabilidad general de anotar un tiro libre es de 0.91? Para determinar esto, podríamos simplemente usar la ecuación de probabilidad binomial y alimentarla con todos los valores posibles de k y sumarlos todos juntos:

$$
P(k\le2)= P(k=2) + P(k=1) + P(k=0) = 6e^{-5} + .002 + .040 = .043  
$$

<!-- In many cases the number of possible outcomes would be too large for us to compute the cumulative probability by enumerating all possible values; fortunately, it can be computed directly for any theoretical probability distribution. The table below shows the cumulative probability of each possible number of successful free throws in the example from above: -->
En muchos casos el número de resultados posibles podría ser demasiado grande para poder calcular la probabilidad acumulada con este método de enumerar todos los valores posibles; afortunadamente, puede ser calculado directamente para cualquier distribución de probabilidad teórica. La Tabla \@ref(tab:CurryCumulativeProb) muestra la probabilidad acumulada de cada número posible de tiros libres exitosos del ejemplo de arriba:

```{r echo=FALSE}
# compute cumulative probability distribution for Curry's free throws

curry_df <- tibble(
  numSuccesses = seq(0, 4)
) %>%
  mutate(
    CumulativeProbability = pbinom(numSuccesses, size = 4, prob = 0.91)
  )

```

<!-- Cumulative probability distribution for number of successful free throws by Steph Curry in 4 attempts. -->
```{r CurryCumulativeProb, echo=FALSE}
kable(curry_df, caption='Distribución de probabilidad acumulada para el número de tiros libres exitosos en los 4 intentos de Steph Curry.', digits=3)
```

<!-- From the table we can see that the probability of Curry landing 2 or fewer free throws out of 4 attempts is 0.043. -->
De la tabla podemos ver que la probabilidad de que Curry anotara 2 o menos tiros libres de un total de 4 intentos es 0.043.

<!-- ## Conditional probability {#conditional-probability} -->
## Probabilidad condicional {#conditional-probability}

<!-- So far we have limited ourselves to simple probabilities - that is, the probability of a single event or combination of events.  However, we often wish to determine the probability of some event given that some other event has occurred, which are known as *conditional probabilities*.    -->
Hasta ahora nos hemos limitado a probabilidades simples - esto es, la probabilidad de un solo evento o combinación de eventos. Sin embargo, frecuentemente deseamos determinar la probabilidad de algunos eventos dependiendo de que otro evento haya ocurrido, lo cual se conoce como *probabilidad condicional*.

<!-- Let's take the 2016 US Presidential election as an example.  There are two simple probabilities that we could use to describe the electorate. First, we know  the probability that a voter in the US is affiliated with the Republican party: $p(Republican) = 0.44$.  We also know the probability that a voter cast their vote in favor of Donald Trump: $p(Trump voter)=0.46$.  However, let's say that we want to know the following: What is the probability that a person cast their vote for Donald Trump, *given that they are a Republican*? -->
Tomemos como ejemplo la elección Presidencial de EUA en 2016. Existen dos probabilidades simples que podríamos usar para describir al electorado. Primero, conocemos la probabilidad de que un votante en EUA esté afiliado al Partido Republicano: $p(Republican) = 0.44$. También conocemos la probabilidad de que un votante dé su voto en favor de Donald Trump: $p(Trump voter)=0.46$. Sin embargo, digamos que queremos saber lo siguiente: ¿Cuál es la probabilidad de que una persona vote por Donald Trump, *dado que esa persona sea Republicana*?

<!-- To compute the conditional probability of A given B (which we write as $P(A|B)$, "probability of A, given B"), we need to know the *joint probability* (that is, the probability of both A and B occurring) as well as the overall probability of B: -->
Para calcular la probabilidad condicional de A dado B (que escribimos como $P(A|B)$, "probabilidad de A, dado B"), necesitamos conocer la *probabilidad conjunta* (esto es, la probabilidad de que ambos A y B ocurran) así como la probabilidad general de B:

$$
P(A|B) = \frac{P(A \cap B)}{P(B)}
$$

<!-- That is, we want to know the probability that both things are true, given that the one being conditioned upon is true.   -->
Esto es, queremos saber la probabilidad de que ambas cosas sean ciertas, dado que aquella sobre la que está condicionada sea cierta.

<!-- A graphical depiction of conditional probability, showing how the conditional probability limits our analysis to a subset of the data. -->
```{r conditionalProbability,echo=FALSE,fig.cap="Representación gráfica de la probabilidad condicional, mostrando cómo la probabilidad condicional limita nuestro análisis a un subconjunto de los datos.",fig.width=8,out.height='50%'}
knitr::include_graphics("images/conditional_probability.png")

```

<!-- It can be useful to think of this graphically. Figure \@ref(fig:conditionalProbability) shows a flow chart depicting how the full population of voters breaks down into Republicans and Democrats, and how the conditional probability (conditioning on party) further breaks down the members of each party according to their vote. -->
Puede ser útil pensar en esto gráficamente. La Figura \@ref(fig:conditionalProbability) muestra un diagrama de flujo que representa cómo el total de la población de votantes se divide en Republicanos y Demócratas, y cómo la probabilidad condicional (condicinada sobre el partido) divide aún a los miembros de cada partido de acuerdo a su voto.

<!-- ## Computing conditional probabilities from data -->
## Calcular probabilidades condicionales a partir de los datos

<!-- We can also compute conditional probabilities directly from data. Let's say that we are interested in the following question: What is the probability that someone has diabetes, given that they are not physically active? -- that is, $P(diabetes|inactive)$. The NHANES dataset includes two variables that address the two parts of this question.  The first (```Diabetes```) asks whether the person has ever been told that they have diabetes, and the second (```PhysActive```) records whether the person engages in sports, fitness, or recreational activities that are at least of moderate intensity.  Let's first compute the simple probabilities. -->
También podemos calcular probabilidades condicionales desde los datos. Digamos que estamos interesados en la siguiente pregunta: ¿Cuál es la probabilidad de que alguien tenga diabetes, dado que no sea una persona físicamente activa? -- esto es, $P(diabetes|inactive)$. La base de datos NHANES incluye dos variables que abordan las dos partes de esta pregunta. La primera (```Diabetes```) pregunta si una persona ha sido enterada de que tenga diabetes, y la segunda (```PhysActive```) registra si una persona se involucra en deportes, fitness, o actividades recreativas que sean de al menos intensidad moderada. Primero calculemos las probabilidades simples.

```{r echo=FALSE}
# Summarize NHANES data for diabetes and physical activity

# drop duplicated IDs within the NHANES dataset
NHANES_diabetes_activity <- 
  NHANES %>% 
  distinct(ID, .keep_all = TRUE) %>% 
  drop_na(PhysActive, Diabetes)

diabetes_summary <- NHANES_diabetes_activity %>%
  count(Diabetes) %>% 
  mutate(
    prob = n / sum(n)
  ) 

physactive_summary <- NHANES_diabetes_activity %>%
  count(PhysActive) %>%
  mutate(
    prob = n / sum(n)
  ) 

```

```{r DiabetesPhysActiveSummary, echo=FALSE}
all_summary <- data.frame(Answer=diabetes_summary$Diabetes, 
                          N_diabetes=diabetes_summary$n,
                          P_diabetes=diabetes_summary$prob,
                          N_PhysActive=physactive_summary$n,
                          P_PhysActive=physactive_summary$prob)

# Summary data for diabetes and physical activity
kable(all_summary, caption='Resumen de datos para diabetes y actividad física')

```


<!-- The table shows that the probability that someone in the NHANES dataset has diabetes is .1, and the probability that someone is inactive is .45.  -->
La Tabla \@ref(tab:DiabetesPhysActiveSummary) muestra la probabilidad de que alguien en la base de datos NHANES tenga diabetes es .1, y la probabilidad de que alguien sean inactivo es .45.

```{r DiabetesPhysActiveSummaryJoint, echo=FALSE}
# compute joint probabilities for diabetes and physical activity

NHANES_diabetes_stats_by_activity <- 
  NHANES_diabetes_activity %>% 
  count(Diabetes, PhysActive) %>% 
  mutate(
    prob = n / sum(n)
  ) 

kable(NHANES_diabetes_stats_by_activity, caption='Joint probabilities for Diabetes and PhysActive variables.')
```

<!-- To compute  $P(diabetes|inactive)$ we would also need to know the joint probability of being diabetic *and* inactive, in addition to the simple probabilities of each. -->
Para calcular $P(diabetes|inactive)$ necesitaríamos también conocer la probabilidad conjunta de ser diabético *y* ser inactivo, además de las probabilidades simples de cada uno.


```{r echo=FALSE}
# compute conditional probability p(diabetes|inactive)

P_inactive <- 
  NHANES_diabetes_activity %>% 
  summarise(
    mean(PhysActive == "No")
  ) %>% 
  pull()

P_diabetes_and_inactive <-
  NHANES_diabetes_stats_by_activity %>% 
  dplyr::filter(Diabetes == "Yes", PhysActive == "No") %>% 
  pull(prob)

P_diabetes_given_inactive <-
  P_diabetes_and_inactive / P_inactive

# P_diabetes_given_inactive
```

<!-- Based on these joint probabilities, we can compute $P(diabetes|inactive)$.  One way to do this in a computer program is to first determine the whether the PhysActive variable was equal to "No" for each indivdual, and then take the mean of those truth values.  Since TRUE/FALSE values are treated as 1/0 respectively by most programming languages (including R and Python), this allows us to easily identify the probability of a simple event by simply taking the mean of a logical variable representing its truth value. We then use that value to compute the conditional probability, where we find that the probability of someone having diabetes given that they are physically inactive is `r I(sprintf('%0.3f',P_diabetes_given_inactive))`. -->
Basados en estas probabilidades conjuntas, podemos calcular $P(diabetes|inactive)$. Una manera de hacer esto en un programa de computadora es primero determinar si la variable PhysActive era igual a "No" en cada individuo, y luego obtener la media de esos valores. Debido a que los valores TRUE/FALSE son tratados como 1/0 respectivamente por la mayoría de los lenguajes de programación (incluidos R y Python), esto nos permite identificar fácilmente la probabilidad de un evento simple obteniendo simplemente la media de una variable lógica que representa si el valor era verdadero. Entonces usamos ese valor para calcular la probabilidad condicional, donde podemos encontrar la probabilidad de que alguien tenga diabetes dado que sea una persona físicamente inactiva es `r I(sprintf('%0.3f',P_diabetes_given_inactive))`.

<!-- ## Independence -->
## Independencia

<!-- The term "independent" has a very specific meaning in statistics, which is somewhat different from the common usage of the term. Statistical independence between two variables means that knowing the value of one variable doesn't tell us anything about the value of the other.  This can be expressed as: -->
El término "independiente" tiene un significado muy específico en estadística, que es un poco diferente del uso común del término. Independencia estadística entre dos variables significa que el conocer el valor de una variable no dice nada sobre el valor de la otra. Esto puede ser expresado como:

$$
P(A|B) = P(A)
$$

<!-- That is, the probability of A given some value of B is just the same as the overall probability of A.  Looking at it this way, we see that many cases of what we would call "independence" in the real world are not actually statistically independent.  For example, there is currently a move by a small group of California citizens to declare a new independent state called Jefferson, which would comprise a number of counties in northern California and Oregon. If this were to happen, then the probability that a current California resident would now live in the state of Jefferson would be $P(\text{Jeffersonian})=0.014$, whereas the probability that they would remain a California resident would be $P(\text{Californian})=0.986$.  The new states might be politically independent, but they would *not* be statistically independent, because $P(\text{Californian|Jeffersonian}) = 0$!  That is, while independence in common language often refers to sets that are exclusive, statistical independence refers to the case where one cannot predict anything about one variable from the value of another variable.  For example, knowing a person's hair color is unlikely to tell you whether they prefer chocolate or strawberry ice cream.  --> 
Esto es, la probabilidad de A dado algún valor de B es la misma que la probabilidad general de A. Mirándolo de esta manera, podemos ver que muchos casos de lo que llamaríamos "independencia" en el mundo real no son realmente estadísticamente independientes. Por ejemplo, actualmente hay un movimiento de un pequeño grupo de ciudadanos de California que quiere declarar un nuevo estado independiente llamado Jefferson, que comprendería a un número de condados del norte de California y Oregon. Si esto pasara, entonces la probabilidad de que un residente actual de California ahora viviera en el estado de Jefferson sería $P(\text{Jeffersonian})=0.014$, mientras que la probabilidad de que se mantuviera siendo un residente de California sería $P(\text{Californian})=0.986$. Los nuevos estados serían políticamente independientes, pero *no* serían estadísticamente independientes, porque ¡$P(\text{Californian|Jeffersonian}) = 0$! Esto es, mientras que independencia en el lenguaje común frecuentemente se refiere a conjuntos que son excluyentes, independencia estadística se refiere al caso donde no se puede predecir nada sobre una variable del valor de otra variable. Por ejemplo, conocer el color de cabello de una persona es improbable que te diga algo sobre si la persona prefiere nieve de chocolate o fresa.

<!-- Let's look at another example, using the NHANES data: Are physical health and mental health independent of one another?  NHANES includes two relevant questions: *PhysActive*, which asks whether the individual is physically active, and *DaysMentHlthBad*, which asks how many days out of the last 30 that the individual experienced bad mental health.  Let's consider anyone who had more than 7 days of bad mental health in the last month to be in bad mental health.  Based on this, we can define a new variable called *badMentalHealth* as a logical variable telling whether each person had more than 7 days of bad mental health or not. Using this new variable, we can then determine whether mental health and physical activity are independent by asking whether the simple probability of bad mental health is different from the conditional probability of bad mental health given that one is physically active. -->
Revisemos otro ejemplo, usando la base de datos NHANES: ¿La salud mental y la salud física son independientes la una de la otra? NHANES incluye dos preguntas relevantes: *PhysActive*, que pregunta si un individuo es físicamente activo, y *DaysMentHlthBad*, que pregunta cuántos días en los últimos 30 días la persona ha experimentado malos días de salud mental. Consideremos a cualquiera que haya tenido más de 7 días de mala salud mental en el último mes como parte de un grupo con mala salud mental. Basados en esto, podemos definir una nueva variable llamada *badMentalHealth* como una variable lógica que nos diga si la persona ha tenido más de 7 días con mala salud mental o no. Usando esta nueva variable, podemos entonces determinar si mala salud mental y actividad física son independientes preguntándonos si la probabilidad simple de mala salud mental es diferente de la probabilidad condicional de mala salud mental dado que la persona sea físicamente activa.

```{r echo=FALSE}
# compute probabilities for mental health and physical activity
NHANES_adult <- 
  NHANES %>%
  dplyr::filter(
    Age >= 18,
    !is.na(PhysActive),
    !is.na(DaysMentHlthBad)
  ) %>% 
  mutate(badMentalHealth = DaysMentHlthBad > 7)

NHANES_MentalHealth_summary <-
  NHANES_adult %>%
  summarize(badMentalHealth = mean(badMentalHealth))

NHANES_MentalHealth_by_PhysActive <-
  NHANES_adult %>%
  group_by(PhysActive) %>%
  summarize(badMentalHealth = mean(badMentalHealth)) 

kable(NHANES_MentalHealth_by_PhysActive)
```

<!-- The overall probability of bad mental health $P(\text{bad mental health})$ is `r I(NHANES_MentalHealth_summary$badMentalHealth)` while the conditional probability $P(\text{bad mental health|physically active})$ is `r I(NHANES_MentalHealth_by_PhysActive$badMentalHealth[2])`.  Thus, it seems that the conditional probability is somewhat smaller than the overall probability, suggesting that they are not independent, though we can't know for sure just by looking at the numbers, since these numbers might be different due to random variability in our sample. Later in the course we will encounter tools that will let us more directly test whether two variables are independent. -->
La probabilidad general de mala salud mental $P(\text{bad mental health})$ es `r I(NHANES_MentalHealth_summary$badMentalHealth)` mientras que la probabilidad condicional $P(\text{bad mental health|physically active})$ es `r I(NHANES_MentalHealth_by_PhysActive$badMentalHealth[2])`. Por lo tanto, parece ser que la probabilidad condicional es un poco menor que la probabilidad general, sugiriendo que no son independientes, aunque no podemos saber con certeza sólo observando estos números, porque estos números podrían ser diferentes debido a variabilidad aleatoria en nuestra muestra. Más tarde en este curso encontraremos herramientas que nos permitirán probar de manera más directa si estas variables son independientes.

<!-- ## Reversing a conditional probability: Bayes' rule {#bayestheorem} -->
## Invertir una probabilidad condicional: regla de Bayes {#bayestheorem}

<!-- In many cases, we know $P(A|B)$ but we really want to know $P(B|A)$. This commonly occurs in medical screening, where we know $P(\text{positive test result| disease})$ but what we want to know is $P(\text{disease|positive test result})$.  For example, some doctors recommend that men over the age of 50 undergo screening using a test called prostate specific antigen (PSA) to screen for possible prostate cancer.  Before a test is approved for use in medical practice, the manufacturer needs to test two aspects of the test's performance. First, they need to show how *sensitive* it is -- that is, how likely is it to find the disease when it is present: $\text{sensitivity} = P(\text{positive test| disease})$.  They also need to show how *specific* it is: that is, how likely is it to give a negative result when there is no disease present: $\text{specificity} = P(\text{negative test|no disease})$.  For the PSA test, we know that sensitivity is about 80% and specificity is about 70%.  However, these don't answer the question that the physician wants to answer for any particular patient: what is the likelihood that they actually have cancer, given that the test comes back positive? This requires that we reverse the conditional probability that defines sensitivity: instead of  $P(positive\ test| disease)$ we want to know $P(disease|positive\ test)$. -->
En muchos casos, conocemos $P(A|B)$ pero lo que realmente queremos conocer es $P(B|A)$. Esto comúnmente ocurre en tamizajes (screenings) médicos, donde conocemos $P(\text{resultado positivo en un test| enfermedad})$ pero lo que queremos conocer es $P(\text{enfermedad|resultado positivo en un test})$. Por ejemplo, algunos doctores recomiendan que los hombres mayores a 50 años se sometan a un screening usando una prueba llamada antígeno prostático específico (APE) para detectar posible cáncer prostático. Antes de que una prueba sea aprobada para su uso la práctica médica, el fabricante debe probar dos aspectos del rendimiento de la prueba. Primero, deben mostrar qué tan *sensible* es -- esto es, qué tan probable es que encuentre la enfermedad cuando está presente: $\text{sensibilidad} = P(\text{prueba positiva| enfermedad})$. También deben mostrar qué tan *específica* es: esto es, qué tan probable es que dé un resultado negativo cuando no hay enfermedad presente: $\text{especificidad} = P(\text{prueba negativa|no enfermedad})$. Para la prueba APE, sabemos que la sensibilidad es cercana al 80% y la especificidad es alrededor de 70%. Sin embargo, estos números no responden a la pregunta que el médico quiere responder acerca de un paciente en particular: ¿cuál es la probabilidad de que el paciente tenga cáncer realmente, dado que la prueba haya salido positiva? Esto requiere que se invierta la probabilidad condicional que define a la sensibilidad: en lugar de $P(prueba\ positiva| enfermedad)$ nosotros queremos saber $P(enfermedad|prueba\ positiva)$.

<!-- In order to reverse a conditional probability, we can use *Bayes' rule*: -->
Para poder invertir la probabilidad condicional, podemos usar la *regla de Bayes*:

$$
P(B|A) = \frac{P(A|B)*P(B)}{P(A)}
$$

<!-- Bayes' rule is fairly easy to derive, based on the rules of probability that we learned earlier in the chapter (see the Appendix for this derivation).   -->
La regla de Bayes es bastante sencilla de derivar, basados en las reglas de probabilidad que aprendimos previamente en este capítulo (ve el Apéndice para esta derivación).

<!-- If we have only two outcomes, we can express Bayes' rule in a somewhat clearer way, using the sum rule to redefine $P(A)$: -->
Si sólo tenemos dos resultados, podemos expresar la regla de Bayes en una manera un poco más clara, usando la regla de la suma para redefinir $P(A)$:

$$
P(A) = P(A|B)*P(B) + P(A|\neg B)*P(\neg B)
$$

<!-- Using this, we can redefine Bayes's rule: -->
Usando esto, podemos redefinir la regla de Bayes:

$$
P(B|A) = \frac{P(A|B)*P(B)}{P(A|B)*P(B) + P(A|\neg B)*P(\neg B)}
$$

<!-- We can plug the relevant numbers into this equation to determine the likelihood that an individual with a positive PSA result actually has cancer -- but note that in order to do this, we also need to know the overall probability of cancer for that person, which we often refer to as the *base rate*. Let's take a 60 year old man, for whom the probability of prostate cancer in the next 10 years is $P(cancer)=0.058$.  Using the sensitivity and specificity values that we outlined above, we can compute the individual's likelihood of having cancer given a positive test: -->
Podemos alimentar estos números a la ecuación para determinar la probabilidad de que una persona con un resultado APE positivo realmente tenga cáncer -- pero nota que para poder hacer esto, también necesitamos saber la probabilidad general de cáncer para esa persona, a la cual nos referimos frecuentemente como la *tasa base*. Tomemos el ejemplo de un hombre de 60 años, para el cual la probabilidad de cáncer de próstata en los siguientes 10 años es $P(cancer)=0.058$. Usando los valores de sensibilidad y especificidad que mencionamos arriba, podemos calcular la probabilidad individual de tener cáncer dado un resultado positivo en la prueba:

$$
P(\text{cancer|test}) = \frac{P(\text{test|cancer})*P(\text{cancer})}{P(\text{test|cancer})*P(\text{cancer}) + P(\text{test|}\neg\text{cancer})*P(\neg\text{cancer})} 
$$
$$
= \frac{0.8*0.058}{0.8*0.058 +0.3*0.942 } = 0.14
$$
<!-- That's pretty small -- do you find that surprising? Many people do, and in fact there is a substantial psychological literature showing that people systematically neglect *base rates* (i.e. overall prevalence) in their judgments. --> 
Eso es una probabilidad bastante baja -- ¿lo encuentras sorpresivo? Para muchas personas lo es, y de hecho existe una sustancial literatura en psicología que muestra que las personas sistemáticamente ignoramos las *tasas base* (i.e. prevalencia general) en nuestros juicios.

<!-- ## Learning from data -->
## Aprender de los datos

<!-- Another way to think of Bayes' rule is as a way to update our beliefs on the basis of data -- that is, learning about the world using data.  Let's look at Bayes' rule again: -->
Otra manera de pensar la regla de Bayes es verla como una manera de actualizar nuestras creencias con base en los datos -- esto es, aprender sobre el mundo usando datos. Veamos la regla de Bayes otra vez:

$$
P(B|A) =  \frac{P(A|B)*P(B)}{P(A)}
$$

<!-- The different parts of Bayes' rule have specific names, that relate to their role in using Bayes' rule to update our beliefs. We start out with an initial guess about the probability of B ($P(B)$), which we refer to as the *prior* probability.  In the PSA example we used the base rate as our prior, since it was our best guess as to the individual's chance of cancer before we knew the test result.  We then collect some data, which in our example was the test result.  The degree to which the data A are consistent with outcome B is given by $P(A|B)$, which we refer to as the *likelihood*.  You can think of this as how likely the data are, given that the particular hypothesis being tested is true.  In our example, the hypothesis being tested was whether the individual had cancer, and the likelihood was based on our knowledge about the sensitivity of the test (that is, the probability of cancer given a positive test outcome). The denominator ($P(A)$) is referred to as the *marginal likelihood*, because it expresses the overall likelihood of the data, averaged across all of the possible values of B (which in our example were disease present and disease absent). -->
Las diferentes partes de la regla de Bayes tienen nombres específicos, que se relacionan con su rol al usar la regla de Bayes para actualizar nuestras creencias. Comenzamos con una conjetura inicial acerca de la probabilidad de B ($P(B)$), al cual nos referimos como la probabilidad *previa* (*prior* probability). En el ejemplo de APE usamos la tasa base como nuestra probabilidad previa, porque era nuestra mejor conjetura sobre la probabilidad de cáncer en la persona antes de conocer los resultados de la prueba. Luego recolectamos datos, que en nuestro ejemplo era el resultado de la prueba. El grado en que la información A es consistente con el resultado B es dado por $P(A|B)$, al cual nos referimos como *probabilidad* (*likelihood*). Puedes considerar ese valor como el qué tan probable es el dato, dado que la hipótesis particular que estamos probando fuera cierta.  En nuestro ejemplo, la hipótesis que está siendo probada era si el individuo tenía cáncer, y la probabilidad estaba basada en nuestro conocimiento acerca de la sensibilidad de la prueba (esto es, la probabilidad de cáncer dado un resultado positivo en la prueba). El denominador ($P(A)$) es referido como la *probabilidad marginal*, porque expresa la probabilidad general del dato, promediado a lo largo de todos los valores posibles de B (que en nuestro ejemplo eran: enfermedad presente y enfermedad ausente).
<!-- The outcome to the left ($P(B|A)$) is referred to as the *posterior* - because it's what comes out the back end of the computation.  -->
El resultado a la izquierda ($P(B|A)$) es referido como la probabilidad *posterior* - porque es lo que se obtiene después de hacer los cálculos.

<!-- There is another way of writing Bayes rule that makes this a bit clearer: -->
Existe otra manera de escribir la regla de Bayes que hace esto un poco más claro:

$$
P(B|A) = \frac{P(A|B)}{P(A)}*P(B)
$$

<!-- The part on the left ($\frac{P(A|B)}{P(A)}$) tells us how much more or less likely the data A are given B, relative to the overall (marginal) likelihood of the data, while the part on the right side ($P(B)$) tells us how likely we thought B was before we knew anything about the data.  This makes it clearer that the role of Bayes theorem is to update our prior knowledge based on the degree to which the data are more likely given B than they would be overall.  If the hypothesis is more likely given the data than it would be in general, then we increase our belief in the hypothesis; if it's less likely given the data, then we decrease our belief. -->
La parte del lado izquierdo ($\frac{P(A|B)}{P(A)}$) nos dice qué tanto es más probable o menos probable el dato A dado B, relativo a la probabilidad general (marginal) de los datos. Mientras que la parte del lado derecho ($P(B)$) nos dice qué tan probable nosotros pensábamos que era B antes de saber nada acerca del dato A. Esto hace más claro que el papel del teorema de Bayes es el actualizar nuestro conocimiento previo basado en el grado en que los datos son más probables dado B de lo que serían en general. Si la hipótesis es mucho más probable dado el dato que se obtuvo de lo que sería en general, entonces incrementamos nuestra creencia en la hipótesis; si es menos probable dado el dato que se obtuvo, entonces disminuimos nuestra creencia.

<!-- ## Odds and odds ratios -->
## Posibilidades (odds) y razón de posibilidades (odds ratios)

<!-- The result in the last section showed that the likelihood that the individual has cancer based on a positive PSA test result is still fairly low, even though it's more than twice as big as it was before we knew the test result. We would often like to quantify the relation between probabilities more directly, which we can do by converting them into *odds* which express the relative likelihood of something happening or not: -->
El resultado de la sección anterior nos mostró que la probabilidad de que la persona tuviera cáncer basada en un resultado positivo de la prueba APE es aún bastante bajo, aunque es más que el doble de lo que pensábamos antes de conocer el resultado de la prueba. A veces nos gustaría cuantificar la relación entre probabilidades de manera más directa, lo cual podemos hacer al convertirlas en *posibilidades* (*odds*) que expresan la probabilidad relativa de que algo suceda o no suceda: 
$$
\text{odds of A} = \frac{P(A)}{P(\neg A)}
$$

<!-- In our PSA example, the odds of having cancer (given the positive test) are: -->
En nuestro ejemplo de APE, las posibilidades (odds) de tener cáncer (dada la prueba positiva) son:

$$
\text{odds of cancer} = \frac{P(\text{cancer})}{P(\neg \text{cancer})} =\frac{0.14}{1 - 0.14} = 0.16
$$

<!-- This tells us that the that the odds are fairly low of having cancer, even though the test was positive.  For comparison, the odds of rolling a 6 in a single dice throw are: -->
Esto nos dice que las posibilidades (odds) de tener cáncer son bastante bajas, aún incluso de que la prueba salió positiva. Para comparar, las posibilidades de obtener un 6 en un dado sencillo son:

$$
\text{odds of 6} = \frac{1}{5} = 0.2
$$

<!-- As an aside, this is a reason why many medical researchers have become increasingly wary of the use of widespread screening tests for relatively uncommon conditions; most positive results will turn out to be false positives, resulting in unneccessary followup tests with possible complications, not to mention added stress for the patient. -->
Como punto aparte, esta es la razón por la que muchos investigadores médicos se han vuelto crecientemente preocupados por el uso generalizado de pruebas de tamizaje para condiciones relativamente poco comunes; la mayoría de los resultados positivos terminarán siendo falsos positivos, resultando en pruebas de seguimiento innecesarias con posibles complicaciones, sin mencionar el estrés añadido al paciente.

<!-- We can also use odds to compare different probabilities, by computing what is called an *odds ratio* - which is exactly what it sounds like.  For example, let's say that we want to know how much the positive test increases the individual's odds of having cancer. We can first compute the *prior odds* -- that is, the odds before we knew that the person had tested positively.  These are computed using the base rate: -->
También podemos usar posibilidades (odds) para comparar diferentes probabilidades, al calcular lo que es conocido como una *razón de posibilidades* (*odds ratio*) - que significa justamente eso. Por ejemplo, digamos que queremos saber qué tanto el resultado positivo en la prueba incrementa las posibilidades (odds) de un individuo de tener cáncer. Primero calculamos las *posibilidades previas* (*prior odds*) -- esto es, las posibilidades antes de saber que la persona salió con un resultado positivo en la prueba. Estas son calculadas usando la tasa base (base rate):

$$
\text{prior odds} = \frac{P(\text{cancer})}{P(\neg \text{cancer})} =\frac{0.058}{1 - 0.058} = 0.061
$$

<!-- We can then compare these with the posterior odds, which are computed using the posterior probability: -->
Luego podemos comparar estas con las *posibilidades posteriores* (*posterior odds*), que son calculadas usando la probabilidad posterior:

$$
\text{odds ratio} = \frac{\text{posterior odds}}{\text{prior odds}} = \frac{0.16}{0.061} = 2.62
$$

<!-- This tells us that the odds of having cancer are increased by 2.62 times given the positive test result.  An odds ratio is an example of what we will later call an *effect size*, which is a way of quantifying how relatively large any particular statistical effect is. -->
Esto nos dice que las posibilidades (odds) de tener cáncer se incrementan por 2.62 veces dado el resultado positivo en la prueba. Una razón de posibilidades (odds ratio) es un ejemplo de lo que después llamaremos un *tamaño del efecto*, que es una manera de cuantificar qué tan relativamente grande es un efecto estadístico en particular.

*Nota de traducción*: los *odds ratio* tienen muchas traducciones diferentes al español, lo que hace complicado explicarlos con un término que se use de manera generalizada en español. En México ha sido muy común llamarles *razón de momios*, pero *momio* es un término de lugares de apuestas que prácticamente sólo se usa en México. En esta traducción usamos la sugerencia de Tapia y Nieto (1993) en su artículo "Razón de posibilidades: una propuesta de traducción de la expresión *odds ratio*" publicado en la revista Salud Pública en México, y tradujimos *odds* como *posibilidades* y *odds ratio* como *razón de posibilidades*.

<!-- ## What do probabilities mean? -->
## ¿Qué significan las probabilidades?

<!-- It might strike you that it is a bit odd to talk about the probability of a person having cancer depending on a test result; after all, the person either has cancer or they don't.  Historically, there have been two different ways that probabilities have been interpreted.  The first (known as the *frequentist* interpretation) interprets probabilities in terms of long-run frequencies.  For example, in the case of a coin flip, it would reflect the relative frequencies of heads in the long run after a large number of flips.  While this interpretation might make sense for events that can be repeated many times like a coin flip, it makes less sense for events that will only happen once, like an individual person's life or a particular presidential election; and as the economist John Maynard Keynes famously said, "In the long run, we are all dead." -->
Podría sorprenderte que es un poco extraño hablar acerca de la probabilidad de que una persona tenga cáncer dependiendo del resultado de una prueba; después de todo, la persona tiene o no tiene cáncer. Históricamente, han habido dos maneras diferentes en que se han interpretado las probabilidades. La primera (conocida como la interpretación *frecuentista*) interpreta las probabilidades en términos de frecuencias a largo plazo. Por ejemplo, en el caso del lanzamiento de moneda, reflejaría las frecuencias relativas de obtener cara en el largo plazo después de un gran número de lanzamientos. Mientras que esta interpretación puede hacer sentido para eventos que pueden ser repetidos muchas veces como un lanzamiento de moneda, hace menos sentido para eventos que sólo sucederán una vez, como la vida de una persona o una elección presidencial en particular; y como dijo famosamente el economista John Maynard Keynes, "En el largo plazo, todos estaremos muertos" ("In the long run, we are all dead").

<!-- The other interpretation of probablities (known as the *Bayesian* interpretation) is as a degree of belief in a particular proposition. If I were to ask you "How likely is it that the US will return to the moon by 2026", you can provide an answer to this question based on your knowledge and beliefs, even though there are no relevant frequencies to compute a frequentist probability.  One way that we often frame subjective probabilities is in terms of one's willingness to accept a particular gamble.  For example, if you think that the probability of the US landing on the moon by 2026 is 0.1 (i.e. odds of 9 to 1), then that means that you should be willing to accept a gamble that would pay off with anything more than 9 to 1 odds if the event occurs. -->  
La otra interpretación de probabilidades (conocida como la interpretación *Bayesiana*) es como un grado de creencia en una proposición particular. Si yo te preguntara "¿Qué tan probable que los EUA regresarán a la Luna en 2026?", tú podrías dar una respuesta a esta pregunta basada en tu conocimiento y en tus creencias, aunque no haya ninguna frecuencia relevante para calcular una probabilidad frecuentista. Una manera en que frecuentemente encuadramos las probabilidades subjetivas es en términos de la disposición a aceptar una apuesta en particular. Por ejemplo, si tu crees que la probabilidad de que EUA llegue a la Luna en 2026 es 0.1 (i.e. posibilidades de 9 a 1), entonces eso significa que deberías estar dispuesto a aceptar una apuesta que pagara posibilidades de 9 a 1 o más si el evento sí ocurriera.

<!-- As we will see, these two different definitions of probability are very relevant to the two different ways that statisticians think about testing statistical hypotheses, which we will encounter in later chapters. -->
Como veremos, estas dos diferentes definiciones de probabilidad son muy relevantes para las dos maneras en que los estadísticos piensan sobre las pruebas de hipótesis estadísticas, que nos encontraremos en capítulos posteriores.

<!-- ## Learning objectives -->
## Objetivos de Aprendizaje

<!-- Having read this chapter, you should be able to: -->
Habiendo leído este capítulo, deberías ser capaz de:

<!-- * Describe the sample space for a selected random experiment. -->
<!-- * Compute relative frequency and empirical probability for a given set of events -->
<!-- * Compute probabilities of single events, complementary events, and the unions and intersections of collections of events. -->
<!-- * Describe the law of large numbers. -->
<!-- * Describe the difference between a probability and a conditional probability -->
<!-- * Describe the concept of statistical independence -->
<!-- * Use Bayes’ theorem to compute the inverse conditional probability. -->

* Describir el espacio muestral para un experimento aleatorio seleccionado.
* Calcular la frecuencia relativa y probabilidad empírica para un conjunto de eventos dado.
* Calcular las probabilidades de eventos sencillos, eventos complementarios, y la unión e intersección de conjuntos de eventos.
* Describir la ley de números grandes.
* Describir la diferencia entre una probabilidad y una probabilidad condicional.
* Describir el concepto de independencia estadística.
* Usar el teorema de Bayes para calcular la probabilidad condicional inversa.



<!-- ## Suggested readings -->
## Lecturas sugeridas

- *The Drunkard's Walk: How Randomness Rules Our Lives*, by Leonard Mlodinow

<!-- ## Appendix -->
## Apéndice 

<!-- Derivation of Bayes' rule -->
<!-- # First, remember the rule for computing a conditional probability: -->
<!-- # We can rearrange this to get the formula to compute the joint probability using the conditional: -->
<!-- Using this we can compute the inverse probability: -->
```{proof, BayesRule, name="Derivación de la regla de Bayes"}

Primero, recuerda la regla para calcular una probabilidad condicional:

$$
P(A|B) = \frac{P(A \cap B)}{P(B)}
$$

Podemos reordenar esto para obtener la fórmula para calcular la probabilidad conjunta usando la condicional:

$$
P(A \cap B) = P(A|B) * P(B)
$$

Usando esto podemos calcular la probabilidad inversa:

$$
P(B|A) = \frac{P(A \cap B)}{P(A)} =   \frac{P(A|B)*P(B)}{P(A)}
$$

```
